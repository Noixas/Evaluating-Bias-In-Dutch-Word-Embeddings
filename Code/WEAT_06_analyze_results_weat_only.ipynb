{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlined testing for word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "unable to import 'smart_open.gcs', disabling that module\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "import fasttext.util\n",
    "from gensim.models.fasttext import FastText, load_facebook_vectors, load_facebook_model\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import string\n",
    "random_state = 1\n",
    "random.seed(random_state) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import bias_neighbors as bias_neighbors\n",
    "import bias_projection as bias_projection\n",
    "import Utils_R as util_r\n",
    "import WEAT\n",
    "import debias_weat as debias_weat\n",
    "from relation import Relation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize imports\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "%matplotlib inline\n",
    "mpl.rc(\"savefig\", dpi=200)\n",
    "mpl.rcParams['figure.figsize'] = (8,8)\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler(color='rc')\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models\n",
    "Methods used to load different combinations of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = \"../Rodrigo-data/Embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fasttext(debiased = False, model_name = 'fasttext_320'):\n",
    "    load_path = embed_path+'FastText/'\n",
    "    model_fast = load_facebook_vectors(load_path+model_name+\".bin\")# old name -> \"cc.nl.300_fasttext.bin\")    \n",
    "    model_fast_debiased = KeyedVectors.load(load_path+\"Debiased/\"+model_name+\".model\") if debiased else None\n",
    "    return [{\"model\":model_fast,\"vec_len\":300,\"name\":model_name,\"model_debiased\":model_fast_debiased,\"load_path\":load_path}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cow(debiased = False, model_name_small = 'cow-320', model_name_big = 'cow-big', big=True, small=True):\n",
    "    load_path = embed_path+'Clips/COW/'\n",
    "    model_cow_small = KeyedVectors.load_word2vec_format(load_path+model_name_small+\".txt\", binary=False,unicode_errors='replace') if small else None# uncomment if there is some problem when using embedding,limit = 603304) #from txt?\n",
    "    model_cow_big = KeyedVectors.load_word2vec_format(load_path+model_name_big+\".txt\", binary=False,unicode_errors='replace') if big else None\n",
    "\n",
    "\n",
    "    model_cow_small_debiased = KeyedVectors.load(load_path+\"/Debiased/\"+model_name_small+\".model\") if small and debiased else None   \n",
    "    model_cow_big_debiased = KeyedVectors.load(load_path+\"/Debiased/\"+model_name_big+\".model\") if big and debiased else None\n",
    "\n",
    "    return [\n",
    "            {\"model\":model_cow_small,\"vec_len\":320,\"name\":model_name_small,\"model_debiased\":model_cow_small_debiased,\"load_path\":load_path},\n",
    "            {\"model\":model_cow_big,\"vec_len\":320,\"name\":model_name_big,\"model_debiased\":model_cow_big_debiased,\"load_path\":load_path}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sonar(debiased = False, model_name_160 = 'sonar-160', model_name_320 = 'sonar-320', big=True, small=True):\n",
    "    load_path = embed_path+'Clips/Sonar/'\n",
    "    model_sonar_160 = KeyedVectors.load_word2vec_format(load_path+model_name_160+\".txt\", binary=False,unicode_errors='replace') if small else None# uncomment if there is some problem when using embedding,limit = 603304) #from txt?\n",
    "    model_sonar_320 = KeyedVectors.load_word2vec_format(load_path+model_name_320+\".txt\", binary=False,unicode_errors='replace') if big else None\n",
    "\n",
    "\n",
    "    model_sonar_160_debiased = KeyedVectors.load(load_path+\"/Debiased/\"+model_name_160+\".model\") if small and debiased else None   \n",
    "    model_sonar_320_debiased = KeyedVectors.load(load_path+\"/Debiased/\"+model_name_320+\".model\") if big and debiased else None\n",
    "\n",
    "    return [\n",
    "            {\"model\":model_sonar_160,\"vec_len\":160,\"name\":model_name_160,\"model_debiased\":model_sonar_160_debiased,\"load_path\":load_path},\n",
    "            {\"model\":model_sonar_320,\"vec_len\":320,\"name\":model_name_320,\"model_debiased\":model_sonar_320_debiased,\"load_path\":load_path}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nlpl(debiased = False, model_name = 'model_nlpl'):\n",
    "    load_path = embed_path+'NLPL/'\n",
    "    \n",
    "    model_nlpl = KeyedVectors.load_word2vec_format(load_path+model_name+\".bin\", binary=True)  \n",
    "    model_nlpl_debiased = KeyedVectors.load(load_path+ \"Debiased/\"+ model_name+\".model\")  if debiased else None\n",
    "\n",
    "    return [{\"model\":model_nlpl,\"vec_len\":100,\"name\":model_name,\"model_debiased\":model_nlpl_debiased,\"load_path\":load_path}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "The main code with functions and other stuff goes down here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_bias_steps(vocab_limited, wv_limited,  model, gender_bias_projection, model_debiased):\n",
    "    \"\"\" Encapsulates the steps related to the projection method.\n",
    "            1. Compute bias projection.\n",
    "            2. Encode lists of male & female words.\n",
    "            3. Generate 2 clusters by using KMeans.\n",
    "                - Get cluster statistic based on how accurate we can separate male and female words. \n",
    "\n",
    "    Parameters:\n",
    "        vocab_limited (list[word]): vocab of model without excluded words (gender specific words).\n",
    "        wv_limited (list[i,vector]): the vectors corresponding to the vocab_limited list.\n",
    "        model : current model from gensim.\n",
    "    \"\"\"    \n",
    "    size = 500   \n",
    "    male, female = bias_projection.get_male_and_female_lists(gender_bias_projection, size)  \n",
    "    male_female = male + female\n",
    "    y_true = [0]*size + [1]*size \n",
    "    X_orig = bias_projection.extract_vectors(male_female, model)#get bias and debiased here\n",
    "    X_debiased = bias_projection.extract_vectors(male_female, model_debiased)\n",
    "    \n",
    "    cluster_metric_a = bias_projection.cluster_and_visualize(male_female, X_orig, X_debiased, random_state, y_true)\n",
    "    return cluster_metric_a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_tests(model,model_vec_len, model_name, exclude_words,cluster_results, downstream_results, model_debiased = None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    cluster_results: Referenced dict, modify in place and reuse per every model. No need to use return.\n",
    "    \"\"\"\n",
    "    print(\"----------------Processing new model!------------------------------------------------------\")\n",
    "    model_name += '__99k_Permutation_WEAT___'\n",
    "    print(\"NAME:\",model_name)\n",
    "    # get the embeddings without the excluded words to make the analysis -R\n",
    "    vocab_limited, wv_limited = util_r.limit_vocab(model, exclude = exclude_words, vec_len=model_vec_len)\n",
    "    ########################################################################################################\n",
    "    # compute bias-by-projection before and after debiasing\n",
    "    gender_bias_projection = bias_projection.compute_bias_by_projection(wv_limited, vocab_limited, model)\n",
    "    bias_projection.report_bias(gender_bias_projection) \n",
    "    ########################################################################################################\n",
    "    up_name = model_name.upper()\n",
    "    print(\"PROJECTION STEP:\",up_name)    \n",
    "    #Projection \n",
    "    # cluster_metric_a = projection_bias_steps(vocab_limited, wv_limited, model, gender_bias_projection, model_debiased)\n",
    "    # cluster_results[model_name] = cluster_metric_a    \n",
    "    # print('Cluster metric results: [orig,debiased] ',cluster_metric_a)\n",
    "    # cluster_results[model_name+' debiased'] = cluster_metric_a[1]\n",
    "    ################################################################################################################\n",
    "    #WEAT\n",
    "    print(\"WEAT ORIGINAL STEP:\",up_name)    \n",
    "    results_weat = WEAT.WEAT_Test(model, model_name,verbose=False)\n",
    "    results_weat_2 = results_weat.copy()\n",
    "    print(\"WEAT DEBIASED STEP:\",up_name)             \n",
    "    results_weat_debiased = WEAT.WEAT_Test(model_debiased, model_name+'_debiased',verbose=False)\n",
    "    results_weat_debiased.drop(['Model','XYAB'], axis=1,inplace=True)\n",
    "    ########################################################################################################\n",
    "    print(\"LATEX:\")\n",
    "    latex_ = util_r.create_latex_table_weat(results_weat_2,results_weat_debiased)\n",
    "    save_latex = '../Rodrigo-data/Results/Latex_tables/latex_'+model_name+'.txt'\n",
    "    print(latex_,file=open(save_latex, 'w'))\n",
    "    ########################################################################################################\n",
    "    #Downstream task\n",
    "    # print(\"(LONG WAIT)DOWNSTREAM STEP:\",up_name)    \n",
    "    # questions_task = \"WEAT_clips/data/question-words.txt\"\n",
    "    # biased_down = Relation(questions_task).test_model_2020(model)\n",
    "    # debiased_down = Relation(questions_task).test_model_2020(model_debiased)\n",
    "    # downstream_results[model_name] = [biased_down[0],debiased_down[0]]       \n",
    "    # print('Downstream biased:',biased_down[0])\n",
    "    # print('Downstream debiased:',debiased_down[0])\n",
    "    # pickle_path= '../Rodrigo-data/Results/downstream_pickle/'\n",
    "    # pickle.dump(biased_down, open( pickle_path+model_name+\"_biased.p\", \"wb\" ) ) #save for later processing\n",
    "    # pickle.dump(debiased_down, open( pickle_path+model_name+\"_debiased.p\", \"wb\" ) )\n",
    "    ########################################################################################################\n",
    "    print(\"END of model:\", up_name)\n",
    "    return results_weat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SAVE PICKE\n",
    "# \"\"\"SAVE PICKLE\"\"\"\n",
    "# modedl_name = 'testtt'\n",
    "# pickle_path= '../Rodrigo-data/Results/downstream_pickle/'\n",
    "# biased_down = ['a','b']\n",
    "# pickle.dump(biased_down, open(pickle_path+modedl_name+\"_biased.p\", \"wb\" ) )\n",
    "# # pickle.dump(debiased_down, open( pickle_path+modedl_name+\"_debiased.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #LOAD PICKE\n",
    "# \"\"\"LOAD PICKLE\"\"\"\n",
    "# favorite_color = pickle.load(open(pickle_path+modedl_name+\"_biased.p\", \"rb\" ) )\n",
    "# favorite_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exclude_words =         debias_weat.load_gender_specific_words() \n",
    "gender_specific_words = debias_weat.load_gender_specific_words()\n",
    "defs, equalize_pairs =  debias_weat.load_def_and_equ_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1817 = {}\n",
    "downstream_1817 = {}\n",
    "debias_save_models = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 50000/50000 [00:00<00:00, 575759.46it/s]----------------Processing new model!------------------------------------------------------\nNAME: fasttext_320__99k_Permutation_WEAT___\nsize of vocabulary: 26171\n\nReport bias by projection: 0.11543014155665221\nPROJECTION STEP: FASTTEXT_320__99K_PERMUTATION_WEAT___\nWEAT ORIGINAL STEP: FASTTEXT_320__99K_PERMUTATION_WEAT___\nWEAT DEBIASED STEP: FASTTEXT_320__99K_PERMUTATION_WEAT___\nLATEX:\nEND of model: FASTTEXT_320__99K_PERMUTATION_WEAT___\nRESULTS WEAT\n                                    Model        XYAB  Effect size d  \\\n0   fasttext_320__99k_Permutation_WEAT___  flowers-in       1.375702   \n1   fasttext_320__99k_Permutation_WEAT___  instrument       1.592843   \n2   fasttext_320__99k_Permutation_WEAT___  european_a      -0.006947   \n3   fasttext_320__99k_Permutation_WEAT___  male_names       1.534239   \n4   fasttext_320__99k_Permutation_WEAT___  math-arts-       1.483715   \n5   fasttext_320__99k_Permutation_WEAT___  science-ar       1.146676   \n6   fasttext_320__99k_Permutation_WEAT___  mental_dis       0.507120   \n7   fasttext_320__99k_Permutation_WEAT___  young_peop       0.521085   \n8   fasttext_320__99k_Permutation_WEAT___  male_names       0.829650   \n9   fasttext_320__99k_Permutation_WEAT___  career-fam       0.890744   \n10  fasttext_320__99k_Permutation_WEAT___  male_terms       0.271428   \n11  fasttext_320__99k_Permutation_WEAT___  career-fam       0.682811   \n12  fasttext_320__99k_Permutation_WEAT___  math-arts-       0.918608   \n13  fasttext_320__99k_Permutation_WEAT___  science-ar       1.122639   \n\n    Significance p WEAT file  \n0         0.000010    Weat-1  \n1         0.000010    Weat-2  \n2         0.509915    Weat-3  \n3         0.000120    Weat-6  \n4         0.000710    Weat-7  \n5         0.007670    Weat-8  \n6         0.128921    Weat-9  \n7         0.166512   Weat-10  \n8         0.021730   Weat-11  \n9         0.042230   Weat-12  \n10        0.249332   Weat-13  \n11        0.098281   Weat-14  \n12        0.035720   Weat-15  \n13        0.009890   Weat-16  \nACTUALLY END................................................................................\n"
    }
   ],
   "source": [
    "if debias_save_models:\n",
    "    models = None\n",
    "    models = load_fasttext(True)  #biggest bottleneck\n",
    "    for model_info in models:\n",
    "        res_weat = compute_all_tests(model_info['model'],model_info['vec_len'],model_info['name'], exclude_words, cluster_1817, downstream_1817, model_info['model_debiased'])\n",
    "        print(\"RESULTS WEAT\")\n",
    "        print(res_weat)\n",
    "        print(\"ACTUALLY END................................................................................\")\n",
    "        model_info = None #free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 50000/50000 [00:00<00:00, 365128.49it/s]----------------Processing new model!------------------------------------------------------\nNAME: cow-320__99k_Permutation_WEAT___\nsize of vocabulary: 48834\n\nReport bias by projection: 0.04150913317099703\nPROJECTION STEP: COW-320__99K_PERMUTATION_WEAT___\nWEAT ORIGINAL STEP: COW-320__99K_PERMUTATION_WEAT___\nWEAT DEBIASED STEP: COW-320__99K_PERMUTATION_WEAT___\n100%|██████████| 50000/50000 [00:00<00:00, 360828.28it/s]LATEX:\nEND of model: COW-320__99K_PERMUTATION_WEAT___\nRESULTS WEAT\n                               Model        XYAB  Effect size d  \\\n0   cow-320__99k_Permutation_WEAT___  flowers-in       1.579854   \n1   cow-320__99k_Permutation_WEAT___  instrument       1.612641   \n2   cow-320__99k_Permutation_WEAT___  european_a       0.721517   \n3   cow-320__99k_Permutation_WEAT___  male_names       1.865969   \n4   cow-320__99k_Permutation_WEAT___  math-arts-       1.758839   \n5   cow-320__99k_Permutation_WEAT___  science-ar       1.338577   \n6   cow-320__99k_Permutation_WEAT___  mental_dis       1.552193   \n7   cow-320__99k_Permutation_WEAT___  young_peop       0.239588   \n8   cow-320__99k_Permutation_WEAT___  male_names       1.432716   \n9   cow-320__99k_Permutation_WEAT___  career-fam       1.559870   \n10  cow-320__99k_Permutation_WEAT___  male_terms       0.405160   \n11  cow-320__99k_Permutation_WEAT___  career-fam       1.417003   \n12  cow-320__99k_Permutation_WEAT___  math-arts-       1.419753   \n13  cow-320__99k_Permutation_WEAT___  science-ar       1.337512   \n\n    Significance p WEAT file  \n0         0.000010    Weat-1  \n1         0.000010    Weat-2  \n2         0.000300    Weat-3  \n3         0.000010    Weat-6  \n4         0.000010    Weat-7  \n5         0.002470    Weat-8  \n6         0.006980    Weat-9  \n7         0.332913   Weat-10  \n8         0.000010   Weat-11  \n9         0.000130   Weat-12  \n10        0.184642   Weat-13  \n11        0.001630   Weat-14  \n12        0.000900   Weat-15  \n13        0.002660   Weat-16  \nACTUALLY END................................................................................\n----------------Processing new model!------------------------------------------------------\nNAME: cow-big__99k_Permutation_WEAT___\nsize of vocabulary: 48834\n\nReport bias by projection: 0.03891669255864782\nPROJECTION STEP: COW-BIG__99K_PERMUTATION_WEAT___\nWEAT ORIGINAL STEP: COW-BIG__99K_PERMUTATION_WEAT___\nWEAT DEBIASED STEP: COW-BIG__99K_PERMUTATION_WEAT___\nLATEX:\nEND of model: COW-BIG__99K_PERMUTATION_WEAT___\nRESULTS WEAT\n                               Model        XYAB  Effect size d  \\\n0   cow-big__99k_Permutation_WEAT___  flowers-in       1.545507   \n1   cow-big__99k_Permutation_WEAT___  instrument       1.548872   \n2   cow-big__99k_Permutation_WEAT___  european_a       0.656499   \n3   cow-big__99k_Permutation_WEAT___  male_names       1.770873   \n4   cow-big__99k_Permutation_WEAT___  math-arts-       1.712939   \n5   cow-big__99k_Permutation_WEAT___  science-ar       1.424569   \n6   cow-big__99k_Permutation_WEAT___  mental_dis       1.387493   \n7   cow-big__99k_Permutation_WEAT___  young_peop       0.691423   \n8   cow-big__99k_Permutation_WEAT___  male_names       1.398706   \n9   cow-big__99k_Permutation_WEAT___  career-fam       1.525922   \n10  cow-big__99k_Permutation_WEAT___  male_terms       0.378339   \n11  cow-big__99k_Permutation_WEAT___  career-fam       1.333808   \n12  cow-big__99k_Permutation_WEAT___  math-arts-       1.667678   \n13  cow-big__99k_Permutation_WEAT___  science-ar       1.460019   \n\n    Significance p WEAT file  \n0         0.000010    Weat-1  \n1         0.000010    Weat-2  \n2         0.004350    Weat-3  \n3         0.000010    Weat-6  \n4         0.000010    Weat-7  \n5         0.000740    Weat-8  \n6         0.013720    Weat-9  \n7         0.097021   Weat-10  \n8         0.000020   Weat-11  \n9         0.000290   Weat-12  \n10        0.201832   Weat-13  \n11        0.003000   Weat-14  \n12        0.000160   Weat-15  \n13        0.000820   Weat-16  \nACTUALLY END................................................................................\n"
    }
   ],
   "source": [
    "if debias_save_models:\n",
    "    models = None\n",
    "    models = load_cow(True)  #biggest bottleneck\n",
    "    for model_info in models:\n",
    "        res_weat = compute_all_tests(model_info['model'],model_info['vec_len'],model_info['name'], exclude_words, cluster_1817, downstream_1817, model_info['model_debiased'])\n",
    "        print(\"RESULTS WEAT\")\n",
    "        print(res_weat)\n",
    "        print(\"ACTUALLY END................................................................................\")\n",
    "        model_info = None #free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 50000/50000 [00:00<00:00, 361660.24it/s]----------------Processing new model!------------------------------------------------------\nNAME: sonar-160__99k_Permutation_WEAT___\nsize of vocabulary: 49505\n\nReport bias by projection: 0.031208526973765843\nPROJECTION STEP: SONAR-160__99K_PERMUTATION_WEAT___\nWEAT ORIGINAL STEP: SONAR-160__99K_PERMUTATION_WEAT___\nWEAT DEBIASED STEP: SONAR-160__99K_PERMUTATION_WEAT___\n100%|██████████| 50000/50000 [00:00<00:00, 354264.81it/s]LATEX:\nEND of model: SONAR-160__99K_PERMUTATION_WEAT___\nRESULTS WEAT\n                                 Model        XYAB  Effect size d  \\\n0   sonar-160__99k_Permutation_WEAT___  flowers-in       1.448992   \n1   sonar-160__99k_Permutation_WEAT___  instrument       1.579580   \n2   sonar-160__99k_Permutation_WEAT___  european_a       0.001080   \n3   sonar-160__99k_Permutation_WEAT___  male_names       0.725754   \n4   sonar-160__99k_Permutation_WEAT___  math-arts-       1.451309   \n5   sonar-160__99k_Permutation_WEAT___  science-ar       1.180736   \n6   sonar-160__99k_Permutation_WEAT___  mental_dis       1.287356   \n7   sonar-160__99k_Permutation_WEAT___  young_peop       0.069756   \n8   sonar-160__99k_Permutation_WEAT___  male_names       0.952219   \n9   sonar-160__99k_Permutation_WEAT___  career-fam       1.436066   \n10  sonar-160__99k_Permutation_WEAT___  male_terms       0.528292   \n11  sonar-160__99k_Permutation_WEAT___  career-fam       1.315211   \n12  sonar-160__99k_Permutation_WEAT___  math-arts-       1.242842   \n13  sonar-160__99k_Permutation_WEAT___  science-ar       1.198990   \n\n    Significance p WEAT file  \n0         0.000010    Weat-1  \n1         0.000010    Weat-2  \n2         0.297983    Weat-3  \n3         0.083791    Weat-6  \n4         0.000470    Weat-7  \n5         0.007260    Weat-8  \n6         0.013430    Weat-9  \n7         0.448984   Weat-10  \n8         0.009170   Weat-11  \n9         0.001340   Weat-12  \n10        0.106091   Weat-13  \n11        0.002420   Weat-14  \n12        0.004170   Weat-15  \n13        0.005120   Weat-16  \nACTUALLY END................................................................................\n----------------Processing new model!------------------------------------------------------\nNAME: sonar-320__99k_Permutation_WEAT___\nsize of vocabulary: 49505\n\nReport bias by projection: 0.028682630164087883\nPROJECTION STEP: SONAR-320__99K_PERMUTATION_WEAT___\nWEAT ORIGINAL STEP: SONAR-320__99K_PERMUTATION_WEAT___\nWEAT DEBIASED STEP: SONAR-320__99K_PERMUTATION_WEAT___\nLATEX:\nEND of model: SONAR-320__99K_PERMUTATION_WEAT___\nRESULTS WEAT\n                                 Model        XYAB  Effect size d  \\\n0   sonar-320__99k_Permutation_WEAT___  flowers-in       1.412814   \n1   sonar-320__99k_Permutation_WEAT___  instrument       1.572064   \n2   sonar-320__99k_Permutation_WEAT___  european_a      -0.490320   \n3   sonar-320__99k_Permutation_WEAT___  male_names       0.528334   \n4   sonar-320__99k_Permutation_WEAT___  math-arts-       1.171619   \n5   sonar-320__99k_Permutation_WEAT___  science-ar       0.994788   \n6   sonar-320__99k_Permutation_WEAT___  mental_dis       1.134103   \n7   sonar-320__99k_Permutation_WEAT___  young_peop      -0.020594   \n8   sonar-320__99k_Permutation_WEAT___  male_names       0.726953   \n9   sonar-320__99k_Permutation_WEAT___  career-fam       1.275882   \n10  sonar-320__99k_Permutation_WEAT___  male_terms       0.445024   \n11  sonar-320__99k_Permutation_WEAT___  career-fam       1.254954   \n12  sonar-320__99k_Permutation_WEAT___  math-arts-       1.092284   \n13  sonar-320__99k_Permutation_WEAT___  science-ar       1.150447   \n\n    Significance p WEAT file  \n0         0.000010    Weat-1  \n1         0.000010    Weat-2  \n2         0.880489    Weat-3  \n3         0.160982    Weat-6  \n4         0.010630    Weat-7  \n5         0.022100    Weat-8  \n6         0.021420    Weat-9  \n7         0.517285   Weat-10  \n8         0.038960   Weat-11  \n9         0.004540   Weat-12  \n10        0.139651   Weat-13  \n11        0.004450   Weat-14  \n12        0.013440   Weat-15  \n13        0.008820   Weat-16  \nACTUALLY END................................................................................\n"
    }
   ],
   "source": [
    "if debias_save_models:\n",
    "    models = None\n",
    "    models = load_sonar(True)  #biggest bottleneck\n",
    "    for model_info in models:\n",
    "        res_weat = compute_all_tests(model_info['model'],model_info['vec_len'],model_info['name'], exclude_words, cluster_1817, downstream_1817, model_info['model_debiased'])\n",
    "        print(\"RESULTS WEAT\")\n",
    "        print(res_weat)\n",
    "        print(\"ACTUALLY END................................................................................\")\n",
    "        model_info = None #free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 50000/50000 [00:00<00:00, 382851.96it/s]----------------Processing new model!------------------------------------------------------\nNAME: model_nlpl__99k_Permutation_WEAT___\nsize of vocabulary: 43768\n\nReport bias by projection: 0.6702604322506505\nPROJECTION STEP: MODEL_NLPL__99K_PERMUTATION_WEAT___\nWEAT ORIGINAL STEP: MODEL_NLPL__99K_PERMUTATION_WEAT___\nWEAT DEBIASED STEP: MODEL_NLPL__99K_PERMUTATION_WEAT___\nLATEX:\nEND of model: MODEL_NLPL__99K_PERMUTATION_WEAT___\nRESULTS WEAT\n                                  Model        XYAB  Effect size d  \\\n0   model_nlpl__99k_Permutation_WEAT___  flowers-in       1.624363   \n1   model_nlpl__99k_Permutation_WEAT___  instrument       1.537925   \n2   model_nlpl__99k_Permutation_WEAT___  european_a       0.493434   \n3   model_nlpl__99k_Permutation_WEAT___  male_names       1.747549   \n4   model_nlpl__99k_Permutation_WEAT___  math-arts-       1.443442   \n5   model_nlpl__99k_Permutation_WEAT___  science-ar       0.765628   \n6   model_nlpl__99k_Permutation_WEAT___  mental_dis       1.368313   \n7   model_nlpl__99k_Permutation_WEAT___  young_peop       0.332843   \n8   model_nlpl__99k_Permutation_WEAT___  male_names       1.481675   \n9   model_nlpl__99k_Permutation_WEAT___  career-fam       1.741585   \n10  model_nlpl__99k_Permutation_WEAT___  male_terms       0.536939   \n11  model_nlpl__99k_Permutation_WEAT___  career-fam       1.138262   \n12  model_nlpl__99k_Permutation_WEAT___  math-arts-       1.415558   \n13  model_nlpl__99k_Permutation_WEAT___  science-ar       1.316624   \n\n    Significance p WEAT file  \n0         0.000010    Weat-1  \n1         0.000010    Weat-2  \n2         0.023040    Weat-3  \n3         0.000010    Weat-6  \n4         0.000840    Weat-7  \n5         0.070951    Weat-8  \n6         0.008280    Weat-9  \n7         0.273703   Weat-10  \n8         0.000010   Weat-11  \n9         0.000050   Weat-12  \n10        0.122031   Weat-13  \n11        0.010580   Weat-14  \n12        0.000890   Weat-15  \n13        0.002250   Weat-16  \nACTUALLY END................................................................................\n"
    }
   ],
   "source": [
    "if debias_save_models:\n",
    "    models = None\n",
    "    models = load_nlpl(True)  #biggest bottleneck\n",
    "    for model_info in models:\n",
    "        res_weat = compute_all_tests(model_info['model'],model_info['vec_len'],model_info['name'], exclude_words, cluster_1817, downstream_1817, model_info['model_debiased'])\n",
    "        print(\"RESULTS WEAT\")\n",
    "        print(res_weat)\n",
    "        print(\"ACTUALLY END................................................................................\")\n",
    "        model_info = None #free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{table}[htb!]\n    \\begin{center}\n\n    \\begin{tabular}{|c|c|c|}\n    \\hline \n        Model &  Original &  Debiased \\\\\n       \\hline\n    fasttext_320 & 0.6744525547445256 & 0.6623566214807091 \\\\\n \\hline\n cow-320 & 0.5131982811540823 & 0.5122774708410067 \\\\\n \\hline\n cow-big & 0.515756087579292 & 0.5180069572334766 \\\\\n \\hline\n sonar-160 & 0.40838126540673786 & 0.3944124897288414 \\\\\n \\hline\n sonar-320 & 0.4294371405094495 & 0.4218364831552999 \\\\\n \\hline\n model_nlpl & 0.43036946812829885 & 0.4334145351197726 \\\\\n \\hline\n  \\end{tabular}\n     \\caption{Downstream task results, before and after debias step}\n\n\\label{tab2}\n\\end{center}\n\\end{table} \n\\begin{table}[htb!]\n    \\begin{center}\n\n    \\begin{tabular}{|c|c|c|}\n    \\hline \n        Model &  Original &  Debiased \\\\\n       \\hline\n    fasttext_320 & 0.576 & 0.605 \\\\\n \\hline\n cow-320 & 1.0 & 1.0 \\\\\n \\hline\n cow-big & 0.999 & 0.999 \\\\\n \\hline\n sonar-160 & 1.0 & 1.0 \\\\\n \\hline\n sonar-320 & 0.998 & 0.998 \\\\\n \\hline\n model_nlpl & 0.552 & 0.995 \\\\\n \\hline\n  \\end{tabular}\n     \\caption{Cluster test results, before and after debias step}\n\n\\label{tab2}\n\\end{center}\n\\end{table} \n"
    }
   ],
   "source": [
    "d_res_latex = util_r.create_latex_table_downstream(downstream_1817)\n",
    "print(d_res_latex)\n",
    "c_res_latex = util_r.create_latex_table_cluster(cluster_1817)\n",
    "print(c_res_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36564bitpytorchp36conda14e9f2ec2c1644a58673c19beabaa9b5",
   "display_name": "Python 3.6.5 64-bit ('pytorch_p36': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}